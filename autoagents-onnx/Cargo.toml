[package]
name = "autoagents-onnx"
version.workspace = true
edition.workspace = true
license.workspace = true
description = "Minimal edge inference runtime for LLMs"
repository.workspace = true
keywords = ["inference", "llm", "edge", "runtime"]
categories = ["science", "algorithms"]
readme.workspace = true

[features]
default = []
cuda = ["ort/cuda"]

[dependencies]
autoagents-llm.workspace = true
# Core dependencies
thiserror = { workspace = true }
log = { workspace = true }
async-trait = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }

# Utilities
chrono = { workspace = true }

# Non-WASM dependencies
[target.'cfg(not(target_arch = "wasm32"))'.dependencies]
tokio = { workspace = true, features = ["rt", "sync", "fs"] }
num_cpus = "1.16"
rand = { workspace = true }
# ONNX Runtime support for native
ort = { version = "=2.0.0-rc.10", features = [
    "copy-dylibs",
    "half",
    "std",
] }
ndarray = { workspace = true }
tokenizers = { workspace = true }
minijinja = { workspace = true }
regex = { workspace = true }

[dev-dependencies]
tokio-test = { workspace = true }
tempfile = { workspace = true }
